{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data and take out id columns\n",
    "new_data = pd.read_csv('data/final_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numeric columns\n",
    "num =['time_in_hospital','num_lab_procedures','num_procedures','num_medications','number_outpatient','number_emergency',\n",
    "'number_inpatient','number_diagnoses']\n",
    "#normalize new_data numeric columns\n",
    "from sklearn.preprocessing import Normalizer\n",
    "transformer = Normalizer().fit(new_data[num])\n",
    "new_data[num] = transformer.transform(new_data[num])\n",
    "new_data[num] = pd.DataFrame(new_data[num], columns= new_data[num].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84432, 151)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dummify\n",
    "new_data = pd.get_dummies(new_data, drop_first = True)\n",
    "new_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #enlabel the columns\n",
    "# new_data = new_data\n",
    "# new_data['admission_type_id'] = pd.Categorical(new_data.admission_type_id)\n",
    "# new_data['discharge_disposition_id'] = pd.Categorical(new_data.discharge_disposition_id)\n",
    "# new_data['admission_source_id'] = pd.Categorical(new_data.admission_source_id)\n",
    "\n",
    "# cat_cols = list(new_data.select_dtypes(include=[object]).columns)\n",
    "# for col in cat_cols:\n",
    "#    new_data[col] = pd.Categorical(new_data[col])\n",
    "\n",
    "# le = preprocessing.LabelEncoder()\n",
    "\n",
    "# col_to_encode = new_data[list(new_data.select_dtypes(include=['category']).columns)]\n",
    "# for col in col_to_encode:\n",
    "#    new_data[col] = le.fit_transform(new_data[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    74817\n",
       "0    74817\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Up-sample Minority Class\n",
    "from sklearn.utils import resample\n",
    "majority = new_data[new_data.target==0]\n",
    "minority = new_data[new_data.target==1]\n",
    "minority_upsampled = resample(minority,replace=True,n_samples=74817,random_state=123)\n",
    "new_data1 = pd.concat([majority, minority_upsampled])\n",
    "new_data1.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112225, 151) (112225,)\n",
      "(37409, 151) (37409,)\n"
     ]
    }
   ],
   "source": [
    "#Spliting to training\n",
    "target = new_data1.target\n",
    "X_train, X_test1, y_train, y_test1 = train_test_split(new_data1, target, test_size=0.25, stratify = target)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test1.shape, y_test1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63324, 151) (63324,)\n",
      "(21108, 151) (21108,)\n"
     ]
    }
   ],
   "source": [
    "#Spliting to testing datasets\n",
    "target = new_data.target\n",
    "X_train1, X_test, y_train1, y_test = train_test_split(new_data, target, test_size=0.25, stratify = target)\n",
    "print(X_train1.shape, y_train1.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop target from training\n",
    "X_train = X_train.drop('target', axis=1)\n",
    "X_test = X_test.drop('target', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #gridsearchcv\n",
    "# from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# classifier = Pipeline([('vect', CountVectorizer(lowercase=False)),\n",
    "#                       ('tfidf', TfidfTransformer()),\n",
    "#                       ('clf', MultinomialNB()),\n",
    "# ])\n",
    "\n",
    "# # parameter tuning with grid search\n",
    "# parameters = {'vect__ngram_range': [(1, 1), (1, 2),(1,3)],\n",
    "#               'vect__max_df': ( 0.7,0.8,0.9,1.0),\n",
    "#               'vect__min_df': (1,2),    \n",
    "#               'clf__alpha': ( 0.022,0.025, 0.028),\n",
    "# }\n",
    "# gs_clf = GridSearchCV(classifier, parameters,n_jobs=-1, verbose=1,cv=5)\n",
    "# gs_clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gs_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.510189351748719"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Fit the model with training\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)\n",
    "## The score (accuracy for classification problems):\n",
    "model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5107165185910566"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#AUC test  \n",
    "from sklearn.metrics import roc_auc_score\n",
    "upsample_AUC_train =roc_auc_score(y_test, model.predict(X_test))\n",
    "upsample_AUC_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  751, 17953],\n",
       "       [   45,  2359]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, model.predict(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
