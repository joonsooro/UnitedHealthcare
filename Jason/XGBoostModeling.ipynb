{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetic7 = pd.read_csv('data/final_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetic7.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetic7.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetic7 = diabetic7.drop(['admission_type_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetic7.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = diabetic7.select_dtypes(include = [\"object\"]).columns\n",
    "numerical = diabetic7.select_dtypes(exclude = [\"object\"]).columns\n",
    "print(\"Number of Categorical features: \" + str(len(categorical)))\n",
    "print(\"Number of Numerical features: \" + str(len(numerical)))\n",
    "diabetic7_categorical = diabetic7[categorical]\n",
    "diabetic7_numerical = diabetic7[numerical]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical= list(categorical)\n",
    "numerical = list(numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in categorical:\n",
    "    diabetic7[i] = le.fit_transform(diabetic7[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetic7.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetic7.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = diabetic7['target']\n",
    "diabetic7 = diabetic7.drop(['target'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#divide the dataset into train/test 7:3?\n",
    "X_train, X_test, y_train, y_test = train_test_split(diabetic7, answer, test_size = 0.3, random_state = 0, stratify=answer, shuffle=True)\n",
    "print(\"X_train : \" + str(X_train.shape))\n",
    "print(\"X_test : \" + str(X_test.shape))\n",
    "print(\"y_train : \" + str(y_train.shape))\n",
    "print(\"y_test : \" + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=XGBClassifier(random_state=0, class_weight = {0:1, 1:8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trees_range = range(10,20, 4)  # OOB score will warning if too few trees\n",
    "train_error2 = []\n",
    "test_error2 = []\n",
    "oob_error = []\n",
    "\n",
    "for n_trees in n_trees_range:\n",
    "    model.set_params(n_estimators=n_trees, random_state=42, scale_pos_weight = 8, max_depth=6, n_jobs = -1)\n",
    "    model.fit(X_train, y_train)\n",
    "    train_error2.append(1 - model.score(X_train, y_train))\n",
    "    test_error2.append(1 - model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(n_trees_range, train_error2, c='red', label='training error')\n",
    "plt.plot(n_trees_range, test_error2, c='blue', label='test error')\n",
    "plt.ylabel('Error')\n",
    "plt.xlabel('Number of trees')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_train, model.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'reg_alpha': 0.2,\n",
    " 'min_samples_split': 10,\n",
    " 'min_samples_leaf': 4,\n",
    " 'max_depth': 110,\n",
    " 'learning_rate': 0.1,\n",
    "\n",
    " 'subsample': 0.5,\n",
    " 'n_estimators': 400,\n",
    " 'min_child_weight': 6,\n",
    " 'gamma': 0.2,\n",
    " 'colsample_bytree': 0.5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=4, random_state=None, shuffle=True),\n",
       "          error_score='raise-deprecating',\n",
       "          estimator=XGBClassifier(base_score=0.5, booster='gbtree', class_weight={0: 1, 1: 8},\n",
       "       colsample_bylevel=1, colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=3, min_child_weight=1, missing=None,\n",
       "       n_estimators=100, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
       "       subsample=1),\n",
       "          fit_params=None, iid='warn', n_iter=10, n_jobs=None,\n",
       "          param_distributions={'n_estimators': [12, 14, 16], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110], 'gamma': [0, 0.2, 0.5, 0.8], 'min_child_weight': [1, 6, 12], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'learning_rate': [0.02, 0.06, 0.1], 'subsample': [0.2, 0.5, 0.9], 'colsample_bytree': [0.1, 0.5, 0.9], 'reg_alpha': [0.2, 0.4, 0.7, 0.9], 'njobs': [-1]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=0)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#randomized searchcv to find the range of the hyperparameters of the XGboost\n",
    "\n",
    "\n",
    "cv = StratifiedKFold(shuffle  = True, n_splits = 4)\n",
    "n_estimators = [12, 14, 16]\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = min_samples_leaf = [1, 2, 4]\n",
    "min_child_weight = [1,6,12]\n",
    "colsample_bytree = [0.1, 0.5, 0.9]\n",
    "gamma = [0, 0.2, 0.5, 0.8]\n",
    "learning_rate =  [0.02, 0.06, 0.1] # default 0.1 \n",
    "max_depth =  [int(x) for x in np.linspace(10, 110, num = 11)]# default 3\n",
    "subsample =  [0.2, 0.5, 0.9]\n",
    "reg_alpha=[0.2, 0.4, 0.7, 0.9] \n",
    "\n",
    "random_para = {'n_estimators': n_estimators,\n",
    "               'max_depth': max_depth,\n",
    "               'gamma':gamma,\n",
    "               'min_child_weight': min_child_weight,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'learning_rate': learning_rate,\n",
    "               'subsample': subsample,\n",
    "               'colsample_bytree': colsample_bytree,\n",
    "               'reg_alpha': reg_alpha,\n",
    "               'njobs': [-1]}\n",
    "\n",
    "rand_search_rf = RandomizedSearchCV(model, random_para, cv=cv)\n",
    "rand_search_rf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking risks scores for variables/groups\n",
    "#take out a hold-out sample of observations\n",
    "#risk-table - for categories \n",
    "#risk features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#auc - validation easily feasible\n",
    "#true positive/false positive rates \n",
    "#classify a group as risk group -> average of highest and lowest risk groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subsample': 0.9,\n",
       " 'reg_alpha': 0.4,\n",
       " 'njobs': -1,\n",
       " 'n_estimators': 16,\n",
       " 'min_samples_split': 5,\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_child_weight': 6,\n",
       " 'max_depth': 10,\n",
       " 'learning_rate': 0.06,\n",
       " 'gamma': 0.8,\n",
       " 'colsample_bytree': 0.9}"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_search_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the model and get auc score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subsample': 0.9,\n",
       " 'reg_alpha': 0.4,\n",
       " 'njobs': -1,\n",
       " 'n_estimators': 16,\n",
       " 'min_samples_split': 5,\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_child_weight': 6,\n",
       " 'max_depth': 17,\n",
       " 'learning_rate': 0.06,\n",
       " 'gamma': 0.8,\n",
       " 'colsample_bytree': 0.9}"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#randomized searchcv to find the range of the hyperparameters of the XGboost\n",
    "\n",
    "cv = StratifiedKFold(shuffle  = True, n_splits = 4)\n",
    "n_estimators = [14,16,18]\n",
    "min_child_weight = [1,6,12]\n",
    "colsample_bytree = [0.9, 0.95,0.99]\n",
    "gamma = [0.8, 0.9]\n",
    "learning_rate =  [0.05, 0.06, 0.07] # default 0.1 \n",
    "max_depth =  range(10,20)# default 3\n",
    "subsample =  [0.9, 0.99]\n",
    "reg_alpha=[0.2, 0.4, 0.7, 0.9] \n",
    "\n",
    "random_para = {'n_estimators': n_estimators,\n",
    "               'max_depth': max_depth,\n",
    "               'gamma':gamma,\n",
    "               'min_child_weight': min_child_weight,\n",
    "               'min_samples_split': [5],\n",
    "               'min_samples_leaf': [2],\n",
    "               'learning_rate': learning_rate,\n",
    "               'subsample': subsample,\n",
    "               'colsample_bytree': colsample_bytree,\n",
    "               'reg_alpha': [0.4],\n",
    "               'njobs': [-1]}\n",
    "\n",
    "rand_search_rf = RandomizedSearchCV(model, random_para, cv=cv)\n",
    "rand_search_rf.fit(X_train, y_train)\n",
    "rand_search_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Grid Search\n",
    "#better practice would be to run randomized searchcv first to narrow down the range\n",
    "#then run gridsearchcv\n",
    "\n",
    "#import stratified K fold \n",
    "cv = StratifiedKFold(shuffle  = True, n_splits = 4)\n",
    "min_samples_split = [4,5,6]\n",
    "min_samples_leaf = [1,2]\n",
    "min_child_weight = [5,6,7]\n",
    "colsample_bytree = [0.4,0.5,0.6]\n",
    "gamma = [0.8]\n",
    "learning_rate =  [0.06] # default 0.1 \n",
    "max_depth =  [17] # default 3\n",
    "n_estimators = [16] # default 100\n",
    "subsample =  [0.9]\n",
    "reg_alpha=[0.4] \n",
    "grid_para = {'n_estimators': n_estimators,\n",
    "               'max_depth': max_depth,\n",
    "               'gamma':gamma,\n",
    "               'min_child_weight': min_child_weight,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'subsample': subsample,\n",
    "               'colsample_bytree': colsample_bytree,\n",
    "               'reg_alpha': reg_alpha,\n",
    "               'njobs': [-1]}\n",
    "#import stratified K fold \n",
    "grid_search_forest = GridSearchCV(model, grid_para, cv=cv , scoring = 'roc_auc') #or roc_auc for scoring\n",
    "grid_search_forest.fit(X_train, y_train)\n",
    "\n",
    "bestparam= grid_search_forest.best_params_\n",
    "bestscore= grid_search_forest.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.6,\n",
       " 'gamma': 0.8,\n",
       " 'max_depth': 17,\n",
       " 'min_child_weight': 7,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 4,\n",
       " 'n_estimators': 16,\n",
       " 'njobs': -1,\n",
       " 'reg_alpha': 0.4,\n",
       " 'subsample': 0.9}"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestparam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "model=XGBClassifier(random_state = 0,colsample_bytree = 0.6,\n",
    " gamma = 0.8,\n",
    " max_depth = 17,\n",
    " min_child_weight= 7,\n",
    " min_samples_leaf= 1,\n",
    " min_samples_split= 4,\n",
    " n_estimators= 16,\n",
    " njobs= -1,\n",
    " reg_alpha= 0.4,\n",
    " subsample= 0.9)\n",
    "#model.set_params(bestparam)\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestparam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "AUC = roc_auc_score(y_test, model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
